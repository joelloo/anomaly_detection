{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c238fa5",
   "metadata": {},
   "source": [
    "# Anomaly detection with autoencoders\n",
    "\n",
    "Testing out variants of autoencoders for anomaly detection. We achieve this by using the autoencoders to reconstruct images of the scene, and computing the reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1442ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/miniconda3/envs/normflow/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z):\n",
    "        raise NotImplementedError(\"Forward pass not implemented\")\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        raise NotImplementedError(\"Inverse pass not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1aa6dd",
   "metadata": {},
   "source": [
    "Implement a masked affine coupling layer that operates directly on the latent vector produced by ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddc560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentMaskedAffineCoupling(Flow):\n",
    "    def __init__(self, b, net):\n",
    "        super().__init__()\n",
    "        self.register_buffer('b', b)\n",
    "        self.net = net\n",
    "        self.scaling = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, z):\n",
    "        z_masked = self.b * z\n",
    "        s, t = self.net(z_masked).chunk(2, dim=1)\n",
    "\n",
    "        s_exp = self.scaling.exp()\n",
    "        s = torch.tanh(s / s_exp) * s_exp\n",
    "\n",
    "        z_out = z_masked + (1 - self.b) * (z * torch.exp(s) + t)\n",
    "        log_det = torch.sum((1 - self.b) * s, dim=list(range(1, self.b.dim())))\n",
    "        return z_out, log_det\n",
    "\n",
    "    def inverse(self, z):\n",
    "        z_masked = self.b * z\n",
    "        s, t = self.net(z_masked).chunk(2, dim=1)\n",
    "        \n",
    "        s_exp = self.scaling.exp()\n",
    "        s = torch.tanh(s / s_exp) * s_exp\n",
    "\n",
    "        z_out = z_masked + (1 - self.b) * (z - t) * torch.exp(-s)\n",
    "        log_det = -torch.sum((1 - self.b) * s, dim=list(range(1, self.b.dim())))\n",
    "        return z_out, log_det\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661770d",
   "metadata": {},
   "source": [
    "Implement a normalising flow class that wraps around pre-specified flow layers, and allows us to do forward passes (image latent vector -> target distribution, in this case multivariate normal), as well as to sample (sample from target distribution -> image latent vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6541d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalisingFlow(nn.Module):\n",
    "    def __init__(self, flows, prior, device):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList(flows)\n",
    "        self.prior = prior # Target distribution to be approximated\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, z):\n",
    "        log_det = torch.zeros(z.shape, device=self.device)\n",
    "        for flow in self.flows:\n",
    "            z, local_log_det = flow(z)\n",
    "            log_det += local_log_det\n",
    "        return z, log_det\n",
    "\n",
    "    def sample(self, sample_shape=None):\n",
    "        if sample_shape:\n",
    "            z = self.prior.sample(sample_shape=sample_shape)\n",
    "        else:\n",
    "            z = self.prior.sample() # No need to specify for multivariate normal\n",
    "\n",
    "        z = z.to(self.device)\n",
    "        for flow in reversed(self.flows):\n",
    "            z, _ = flow.inverse(z)\n",
    "        return z\n",
    "    \n",
    "    def get_prior_log_prob(self, z):\n",
    "        return self.prior.log_prob(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ad6c32",
   "metadata": {},
   "source": [
    "Set up neural network classes needed for the flow layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b474f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        if num_layers == 1:\n",
    "            layers = [nn.Linear(in_size, 2*in_size)]\n",
    "        else:\n",
    "            layers = [nn.Linear(in_size, hidden_size, bias=True), nn.LeakyReLU()]\n",
    "            for i in range(num_layers - 2):\n",
    "                layers += [nn.Linear(hidden_size, hidden_size, bias=True), nn.LeakyReLU()]\n",
    "            layers += [nn.Linear(hidden_size, 2*in_size, bias=True)]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a225c",
   "metadata": {},
   "source": [
    "Implements a convolutional autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d90066",
   "metadata": {},
   "source": [
    "Implements building blocks like encoders and decoders, that can be use as part of a VAE or a VAE + NF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c45ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarEncoder(nn.Module):\n",
    "    def __init__(self, latent_size=64, kernel_size=5, img_height=32, channels=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, kernel_size),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        # Calculate the output size of the image tensor after 4 convolution layers\n",
    "        out_h = img_height\n",
    "        out_w = img_height\n",
    "        for i in range(4):\n",
    "            out_h, out_w = self.convOutputShape((out_h, out_w), kernel_size)\n",
    "        \n",
    "        self.flattened_size = out_h * out_w * 128\n",
    "        self.latent_img_height = out_h\n",
    "        \n",
    "        self.fc_mu = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, latent_size, bias=True)\n",
    "        )\n",
    "        \n",
    "        self.fc_sigma = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, latent_size, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.conv(x).view(x.shape[0], -1)\n",
    "        mu = self.fc_mu(z)\n",
    "        sigma = torch.exp(self.fc_sigma(z)) + 1e-7\n",
    "        return mu, sigma\n",
    "    \n",
    "    def convOutputShape(self, h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "        if type(kernel_size) is not tuple:\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        h = math.floor( ((h_w[0] + (2 * pad) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n",
    "        w = math.floor( ((h_w[1] + (2 * pad) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n",
    "        return h, w\n",
    "    \n",
    "class VarDecoder(nn.Module):\n",
    "    def __init__(self, flattened_size, latent_img_height, latent_size=64, kernel_size=5, channels=3):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_size, flattened_size)\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, channels, kernel_size)\n",
    "        )\n",
    "        self.latent_img_height = latent_img_height\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.fc(x).view(x.shape[0], 128, self.latent_img_height, self.latent_img_height)\n",
    "        im = self.conv(z)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f17b00",
   "metadata": {},
   "source": [
    "Set up classes that put the previous components together into the form of a VAE, and VAE + NF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3127e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, device, flows = None, latent_size=64, kernel_size=5, img_height=32, channels=3):\n",
    "        super().__init__()\n",
    "        self.encoder = VarEncoder(latent_size, kernel_size, img_height, channels)\n",
    "        self.decoder = VarDecoder(self.encoder.flattened_size, self.encoder.latent_img_height)\n",
    "        self.device = device\n",
    "        self.flows = flows\n",
    "        self.latent_size = latent_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        z0 = self.reparameterize(mu, sigma)\n",
    "        \n",
    "        if self.flows is None:\n",
    "            zk = z0\n",
    "            var_loss = -0.5 * torch.sum(1 + torch.log(sigma) - mu.pow(2) - sigma)\n",
    "        else:\n",
    "            log_pi = torch.log(torch.tensor(2 * np.pi))\n",
    "            log_sigma = torch.log(sigma)\n",
    "            \n",
    "            assert(not torch.any(torch.isnan(log_sigma)))\n",
    "            assert(not torch.any(torch.isnan(z0)))\n",
    "            assert(not torch.any(torch.isnan(mu)))\n",
    "            \n",
    "            log_prob_z0 = torch.sum(\n",
    "                -0.5 * log_pi - log_sigma - 0.5 * ((z0 - mu) / sigma) ** 2, \n",
    "                axis=1)\n",
    "            \n",
    "            zk, log_det = self.flows(z0)\n",
    "            log_prob_zk = torch.sum(-0.5 * log_pi - 0.5 * (zk**2), axis=1)\n",
    "            \n",
    "            var_loss = torch.mean(log_prob_z0) - torch.mean(log_prob_zk) - torch.mean(log_det)\n",
    "            \n",
    "        im = self.decoder(zk)\n",
    "        return im, mu, sigma, var_loss\n",
    "    \n",
    "    def reparameterize(self, mu, sigma):\n",
    "        epsilon = torch.randn_like(mu, device=self.device)\n",
    "        z = mu + sigma * epsilon\n",
    "        return z\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        # Sample from N(0, 1)\n",
    "        z = torch.randn((batch_size, self.latent_size), device=self.device)\n",
    "        if self.flows is not None:\n",
    "            z, _ = self.flows(z)\n",
    "        im = self.decoder(z)\n",
    "        return im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8469433",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Load the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4b6a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaded in data.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Transformations applied on each image => make them a tensor and discretize\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = datasets.CIFAR10(root=\"../../nf_tutorial/data\", train=True, transform=transform, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [42000, 8000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = datasets.CIFAR10(root=\"../../nf_tutorial/data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Define the data loaders. We currently do not use the validation and test sets.\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "print(\"Loaded in data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68ce56",
   "metadata": {},
   "source": [
    "### Convolutional autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f708462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e1c4e0",
   "metadata": {},
   "source": [
    "### Variational autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf92ce",
   "metadata": {},
   "source": [
    "Set up the models, hyperparameters and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167a5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b92e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss(x, y):\n",
    "    return torch.sum((x - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203336c4",
   "metadata": {},
   "source": [
    "Instantiate a VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6a66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a4d70",
   "metadata": {},
   "source": [
    "Training the VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3dd762",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:21<00:00, 29.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [10496/42000 (100%)]\tLoss: 2854.261230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:21<00:00, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10496/42000 (100%)]\tLoss: 2127.136719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10496/42000 (100%)]\tLoss: 1765.260986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [10496/42000 (100%)]\tLoss: 1855.467163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [10496/42000 (100%)]\tLoss: 1512.235107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:21<00:00, 30.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [10496/42000 (100%)]\tLoss: 1471.182251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:20<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [10496/42000 (100%)]\tLoss: 1377.500244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:20<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [10496/42000 (100%)]\tLoss: 1318.766602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:20<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [10496/42000 (100%)]\tLoss: 1299.241821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [10496/42000 (100%)]\tLoss: 1214.291382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [10496/42000 (100%)]\tLoss: 1224.226929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [10496/42000 (100%)]\tLoss: 1188.414673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [10496/42000 (100%)]\tLoss: 1186.459717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [10496/42000 (100%)]\tLoss: 1147.807251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [10496/42000 (100%)]\tLoss: 1135.616577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [10496/42000 (100%)]\tLoss: 1142.939941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [10496/42000 (100%)]\tLoss: 1126.245239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [10496/42000 (100%)]\tLoss: 1105.225098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [10496/42000 (100%)]\tLoss: 1101.928711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:22<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [10496/42000 (100%)]\tLoss: 1081.996094\n"
     ]
    }
   ],
   "source": [
    "optimizer =  torch.optim.Adam(vae.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "for epoch in range(n_epochs):\n",
    "    progressbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_n, (x, n) in progressbar:\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, mu, sigma, var_loss = vae(x)\n",
    "        #loss = elbo_loss(x.detach(), outputs.detach(), mu.detach(), sigma.detach())\n",
    "        #loss = elbo_loss(x, outputs, mu, sigma)\n",
    "        loss = recon_loss(x, outputs) + var_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progressbar.update()\n",
    "    progressbar.close()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_n * len(x), len(train_loader.dataset),\n",
    "                       100. * batch_n / len(train_loader),\n",
    "                       loss.item()))\n",
    "    \n",
    "torch.save(vae.state_dict(), \"../../nf_tutorial/saved_models/vae.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd872e7",
   "metadata": {},
   "source": [
    "Sampling from the trained normalising flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a09fad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeRElEQVR4nO2dXahk13Xn/+tUnfq4VXW/ulutVluMFI8hmJDIphEeYoInIUFjArIhGPvB6MFEIdgwhuRBeJhYhnlwhrGNHwYP7bGIMnj8MbGNxWBm4hEBkxfFbUeWZGuSOB7JaqnVX/fW7apb3+eseahSaIn93/eq7711O97/HzRd96za56yz66w6Vftfay1zdwghfvHJjtsBIcRyULALkQgKdiESQcEuRCIo2IVIBAW7EIlQPchgM3sAwOcBVAD8V3f/dOz5nU7LT55YD+8rr9FxFaIOmk/5mIyfmltJbWYVagPxo5Lx90wzvrsokXHRfVrYF4vssHQ+H+yc5yZuZJJuzI+imFFbGZGIvYz5wbZHzjlyXpFDRW+dhfPrqkJcKSOXIgvd61evodfrBSf5loPd5lHxnwH8NoCLAL5vZk+4+0/YmJMn1vHov/9o0JafPkuPtT4Jb8+LK3RMu7VBbbNsTG2NWouPm4Qv1M3OCh1TzfnF7SiozSLjqlV+FWSVOtnOX+rReEhtsUCazrj/pYdtGbjvO9vXqW0cOdZkd0Rt0yI8j7PxgI4pnFxwAAaR+cj4/Qq92Tq1rQzDczLhQ2BF2PipP/kUHXOQj/H3A/ipu//M3ScAvgrgwQPsTwhxhBwk2M8CeOmmvy8utgkhbkOOfIHOzB42swtmdqHX2z3qwwkhCAcJ9pcB3H3T329ZbHsd7n7e3c+5+7lOh38fFkIcLQcJ9u8DeJuZ3WtmNQAfBPDE4bglhDhsbnk13t1nZvYxAP8bc+ntMXf/cWyMZRVUW6tBW73Y5uMq4dVzm/FV2PEsIsshp7Yiosh08gbZH1/NrkT0k1repLZyylefGxX+Hs3WiouSy1odpm0C8IyrAoPICvmArPD3d/hcjUdcJemO+Ar5dMht5TB8HUxLfu1Mxnx/FeP+RxRYrNf46n+jHVaOpgO+vH+1EX5dYsrggXR2d/8OgO8cZB9CiOWgX9AJkQgKdiESQcEuRCIo2IVIBAW7EIlwoNX4N4tZhqqF5avm8BU6bkIyhiZcXUMeMRpX3rCxwuWfIgvrct7nEklGstAAYNriQkm1jLwPszQpAHkRHpdHXuoskulnJZfeJiO+T9sN+zgd9OmY4Ta37W53qa035LLihGTSzW7coGNG3qM2M37Oqzn3o7m5SW0TovStnggnNQHAiWFY9qyW/LrXnV2IRFCwC5EICnYhEkHBLkQiKNiFSITlrsZnJZrtcELA4CpfIq+xVc4qX82uR1aRs7AgACBeIy2rhFN0s0gGhOfcx2aDn3NZ8pemNL5KW+bhlfVmnY/JwJNCvMonq+Y8uSMjySle8jTnfo+vxm/1eHLKpSFfWS9ubAW3Z1OuQDhure7CZJWrJKdv8PlfueNacHtj9046Jq+FS6Flkfu37uxCJIKCXYhEULALkQgKdiESQcEuRCIo2IVIhCUnwhiySljKWVnh8gk8nGhScy4Zzer8fawWkbVyiyQzWFhqqsy4vFZZ4fLaONLep1rhyTVlJZL44WHpsBzwuYrVThtH5uN6LyxrAUC/H56rSzs84elSr0ttF7vcdrV3ldpq43DCyCjjk78eqf83bPLXZTXSoqpTRGrQDdeC22cdnpSFBqmFF2ltpju7EImgYBciERTsQiSCgl2IRFCwC5EICnYhEuFA0puZvQCgB6AAMHP3c9HnO5CTNkQrecSVGbFFaqdVIqc2A2+7VK/zjKcWSYizWkQmK7kUUhlGmvUYl12G4PtskCy1qnM5iZT4AwDUI/2wKrNIfb1eWGrqX+Pz+9JFLsu99OrPqW13xGXbwSzs/2rGJdHBiNsaTW7Lhvw16995F7Wt1cMyWqUebpUGALVW+PrOKjxr8zB09n/t7uEcPSHEbYM+xguRCAcNdgfwl2b2AzN7+DAcEkIcDQf9GP9ud3/ZzO4A8F0z+7/u/r2bn7B4E3gYAO44xWtnCyGOlgPd2d395cX/VwB8C8D9geecd/dz7n5uba19kMMJIQ7ALQe7mbXMrPPaYwC/A+C5w3JMCHG4HORj/GkA3zKz1/bz3939f8UGZFmGZitccLAkGWUA0EZY2qo0uWaUldyW5/zrxCppTwUAtVq4aOBszH3HkGQnASjzSKHKMZfl8gaXeKZE6psUXHqrRYpKjmKy4pjLckOEC0QOS559d7XoUttOj7dk2upzMai+G74ObnR44cvc+Gu2y2RgAOWMy3K7/Ui7qa3w9Viu8msga5HXM5J5d8vB7u4/A/BrtzpeCLFcJL0JkQgKdiESQcEuRCIo2IVIBAW7EImw1IKTMAAWfn9pr4R7VwFAKw/LJM06l9fqxiWjosolko0278lVI/3jZiPeo2w04fvrlVxCm8y41LTN6yui7eFxzSp/X8/rG9RWjcib4zGXqHw7LL31+lwaunR5Sm3DrYi8OeDzuN0KX1d35Vw2HN2IFB0lBVMBYBppIpjHerARCdbAz7nIyFxZRK6jFiHELxQKdiESQcEuRCIo2IVIBAW7EImw1NX4zDK0SGJFK5KMsd4O2/Kc15LjaR9ANuUr9Su18CoyAGAarp9mdT6NN6Z8hbnf4/XCptd5OvB0zFeLt4lCsTPmc2Vtvqq+ii617ZLWSgBQ6YVXu+0SVxmaU54kMxjsUNt0xP1v5p3w/hDeDgCr1uV+5Fy5qBX82ikj16pb+DqwSHHAVjO8vyzSy0t3diESQcEuRCIo2IVIBAW7EImgYBciERTsQiTCUqU3M0OjHk5CqZVcemtnYRmq3eJjyozLa9mYJ8LAuHwyq5BaeAM+pkJkFQBYrfFkjMst3iapGqld1x6Hk3KqDS5PZc73VzM+V8UmTwBa8evB7XdM+TnfdZ1fjsXmSWqbRCTMohFuobQZqSWH+llqWo34X63wpKeMuwgn4ypNXifPnOww0lFMd3YhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwp7Sm5k9BuB3AVxx919ZbNsE8DUA9wB4AcAH3H17r31lBtTycCZPw3lWUN4g8k+Du59VeE07ZBHbgGepVS1s80akfVIky2vs/Fj5dS6V5Stb1NawsIxTrfBsLTTWua3D57idcR8xCMulZ3OeKXev8Wug14jUwit4O69pNfxar5/kx6rciLXD4hpaHqlr18i5LFfJwtd3FqmVWCX7s4jUu587+58BeOAN2x4B8KS7vw3Ak4u/hRC3MXsG+6Lf+htvJQ8CeHzx+HEA7ztct4QQh82tfmc/7e6XFo9fxbyjqxDiNubAC3Tu7oj8SM/MHjazC2Z2YWubt60VQhwttxrsl83sDAAs/r/Cnuju5939nLuf29wI/05ZCHH03GqwPwHgocXjhwB8+3DcEUIcFfuR3r4C4D0ATprZRQCfBPBpAF83s48AeBHAB/Z1NMtQzcOyhs14EUUm18G5RIIOlzow4zIOTnI5aUK68dRGkdZKLX5e2f/jslx/EM4aA4DxhGf0VTphuebkiMs4lYjMN5rwSySfRCRMhH3MVnk2X/5WXgTSLq5TW+sK/3rYH4clwE6kVVO2zs95LeO22TqXFTstXkB0pX0ifKwW/yTcqIev71jByT2D3d0/REy/tddYIcTtg35BJ0QiKNiFSAQFuxCJoGAXIhEU7EIkwlILTgIOGMkMKrlEVZAif9VYX7ZIbzMUREMDgH6k+GKdyEZdLl3tdi9S26TCCzb2weWk7OfUhB2SIVhr8/ltrnMJzQt+ifQ3uQTY3g0f72z7Ljpmq8qzAF/u8Nds9BLvEddukHMjvdIAYJUrgBjMuITZrkXmuMV32iLZm7Uan/tmMyzlmXq9CSEU7EIkgoJdiERQsAuRCAp2IRJBwS5EIixZejMAYeliPOWyy5AoWxVwyWtlyptezaa8h1Z1xOUTVMJS39VrPHvt2t+/Qm2vbvEsqfEuP7fWmEuOzWY4m2u3znul+ZDLSbUKtzVZvzEAIH7U+3x/jYzLU40GL5jZbI+pbUzkvEadH6te5ZJibZ0Xt8QGl0s7m+HMNgBYWw3vc3WNn3OnHc6Iq2Q8o1N3diESQcEuRCIo2IVIBAW7EImgYBciEZa6Gu/umI7DSQuzHq9NVi3CiTDTHl/Nzld4Nyq7wuuPnc24Hy8ULwe37zz9LB2z9fMdars44ivuRcFX+JsT7v/aWnj1uazx+chynhTSWuUr3WWN+9Ek9QF3V/lrNmrzOm31ktdjO3OaKygNUm+w3uG+V1o8MWjt5J3Ulm1wleeOVd5aYXUtrJQ0alwVyImakJlW44VIHgW7EImgYBciERTsQiSCgl2IRFCwC5EI+2n/9BiA3wVwxd1/ZbHtUQC/D+Dq4mmfcPfv7OeABcLSwDDS/im7EZaodksuC1W63GYDLrv0ZlzyeuVKuPjbpWd5Yspgh0tvz3uX2tpDnlSxUeUS1YzIcll9nY5p1rj0Vn/LWX6sMU+EaU3CtlbBx3TqXGo6EfF/sMIlzLVp+HibLZ4YdNc6T1qpn+bSW9FZp7bTJ7htZT28zxMnuYxWXQknyWSVg0lvfwbggcD2z7n7fYt/+wp0IcTxsWewu/v3AGwtwRchxBFykO/sHzOzZ8zsMTPjibdCiNuCWw32LwB4K4D7AFwC8Bn2RDN72MwumNmFrW3+PVQIcbTcUrC7+2V3L9y9BPBFAPdHnnve3c+5+7nNDf77ZiHE0XJLwW5mZ2768/0Anjscd4QQR8V+pLevAHgPgJNmdhHAJwG8x8zuA+AAXgDwB/s5WOnAaBqW2CYFf98ZT8OZcl5wea3f5xLa+AofN53wlky4Gs6I++HlLj/Wi1ep7ZU17uNqpJVQv6xT2x11Uptsl0tep+7i9f96ZZfaapHsu61ReK58Z42OaWf8WJMxz5brZFyyG68R6a3N52N9LdJ2aZ37PyVtnABgtc1r17Vb4desmvE6il4l14DxONoz2N39Q4HNX9prnBDi9kK/oBMiERTsQiSCgl2IRFCwC5EICnYhEmHp7Z8MYcmAiwwAUd7QI4UoAQBjLidVqnxcr8fTAC6SPlSjEf9l4CsrfIqnXX7WvdM8E20y5bb2JCxRDSIFLF/N+P5ODHmG3anxgNrGlfAcD+wSHTMClxtHE14ItIgUWSxn4fmo5ly+nDa4vNap8fnIVricd/okz6SrkVZOyPn8onzz92nd2YVIBAW7EImgYBciERTsQiSCgl2IRFCwC5EIS5XezIBKJSxPVCN9w8qVsIxWi2RyzeqR/UUy7PJTPDupSaSy6iqX3tad91i7Svp1AcAg0nOuyYeh1wobVytcXhsOeEbZpMsvke7dObVZNzwnw20+5sddXjhy2OfzsTvgBT/XToVltLLg0ltzJdI7boXPVdnm+6y11qkNq6RHXMavbyvZGH5t684uRCIo2IVIBAW7EImgYBciERTsQiTCklfjM1TylaCtNF77rVINr6zX23xlN5vwumSFh30AgGZ2jdrOnAqv0l69+146ZrrGE3LqV69T22oWSbjY5FV6O2SF/3TnTHA7AHTKU9RWOc3nalTl858PwivTN/q8Jl95mWQ8AShmkRZbJbetZOH5z5s8CWlS44k1k0ibskZE5UHERxhZxfdIeLKafJHcMN3ZhUgEBbsQiaBgFyIRFOxCJIKCXYhEULALkQj7af90N4A/B3Aa81Jx593982a2CeBrAO7BvAXUB9wjWR//RFgbqFcjUhmpMWZFJCmhxmWh3Uj9rkbGpabLWfj0Nhu8ndS1azwBZS1Sn64fkQdPDrgs16muB7fXs4hc1+EJF5nz12W6y+exLEibrzGvhdfb5fM42OWS1ywia836Yelt0OXHyq9zHxsZT9YZZJG6dl2uieUVcm45HzMk137pXFLcz519BuCP3P3tAN4F4KNm9nYAjwB40t3fBuDJxd9CiNuUPYPd3S+5+w8Xj3sAngdwFsCDAB5fPO1xAO87Ih+FEIfAm/rObmb3AHgHgKcAnHb31+oCv4r5x3whxG3KvoPdzNoAvgHg4+7+usoE7u4gpd/N7GEzu2BmF7a2ugfxVQhxAPYV7GaWYx7oX3b3by42XzazMwv7GQBXQmPd/by7n3P3c5ub64fgshDiVtgz2M3MMO/H/ry7f/Ym0xMAHlo8fgjAtw/fPSHEYbGfrLdfB/BhAM+a2dOLbZ8A8GkAXzezjwB4EcAH9tqRWYZaLVw7y+pcCjFi6ld5XbLqDpfeUPLsqnGkNVR7I+z75S0uuTTakey1XS6v1cDlsHoktalOap1Nc164bnuNXwbtgo+r7/DXLBuF97lTcCnvxi5vvbXd5XLYNa7AYuThbEo33lppk2RZAkBZ4ZmKGw3e4ml7wP1npeuaEeltQNS6suRj9gx2d/9rgF55v7XXeCHE7YF+QSdEIijYhUgEBbsQiaBgFyIRFOxCJMJSC04CgJGknHrOJZlZGR6UR4pKDp1nQlUynhk0GnJZblaGM6gqkUy5stKltq0ZaeEDYH2dS3YnIz9OuvOuk8HtJ+o8+85r4RZJANDo82yz6ojv83JBss2c62Q/73EpdTjiktK4wWW0a9PwdZBvr/P9tbnsmUfalI2qPJxOjrk8e7IIy8StNp/7XdLmKSa96c4uRCIo2IVIBAW7EImgYBciERTsQiSCgl2IRFiq9JZZhgaRgCYll2RqCMsnQyLJAYBXI4X3drikgQkvKNjvhbO8phOe/dUvuK0ZKfRoGfexbPD3aGuEJa/JRqTIZp1nCFZWuI/jKu+J1t4Nv86nelymvKvDbX/XD5ZLAABcjxSqXC/Csly/eJGOqbe4BLgduT0Wq/zaeXXKfZxWwq/ZqXUu1w1WwhJbESnCqju7EImgYBciERTsQiSCgl2IRFCwC5EIS12NL8sZJrvhFkpFrC7cKLxa2d3hq6bTgicE3OjzVdPRlNu2roRXhHfHN4LbASCfhn0HgNK4rZXxFfIckaJrJAEFk0j7pEits2kkuaNa4/eKjCSuNFt8db/T5vOxFlEuxn0+H6NK+Bq5EZlCv8zPq1mNJD1tcwXoUiQxaxiuwo7JjNe0q7bCakdZHKz9kxDiFwAFuxCJoGAXIhEU7EIkgoJdiERQsAuRCHtKb2Z2N4A/x7wlswM47+6fN7NHAfw+gKuLp37C3b8T25ebYVgLJ0+Mb3DZBTOSREBqwgHAwLi20s+63Nbj9cy2r4db+LzS3aFjsBOphReR3rINLoc1m1xG66+Fx7VW+Jh8zG31iMw3jbTK8mb40ur2eN29MTaorcEPhXbJ5bDZTlgWzVZ4ksnOmMtXRaT90x0z7mRjjSfCjCthGS0jsQIAFQvXwptFEsr2o7PPAPyRu//QzDoAfmBm313YPufu/2kf+xBCHDP76fV2CcClxeOemT0P4OxROyaEOFze1Hd2M7sHwDsAPLXY9DEze8bMHjMz/hlMCHHs7DvYzawN4BsAPu7uNwB8AcBbAdyH+Z3/M2Tcw2Z2wcwubG11D+ywEOLW2Fewm1mOeaB/2d2/CQDuftndC3cvAXwRwP2hse5+3t3Pufu5zUhzAyHE0bJnsJuZAfgSgOfd/bM3bT9z09PeD+C5w3dPCHFY7Gc1/tcBfBjAs2b29GLbJwB8yMzuw1yOewHAH+y5J3dgHJYGykjtrNksbDPj71X1gssWzQFvW9Sr8pZS3uwEt+eR7LsbdS5r1Zy3XapEMsr6Yy7n7ZJ2TZeySC08khkGACc2efbdbMylpmIazmK0IZe1ykgtuemUz+NKpDVUZRDOYpxOuVzXj7RQmuQ8+w6rXEqtXg9newLAZG09uL3T5/JgsxGWgcuDSG/u/tcAQmcY1dSFELcX+gWdEImgYBciERTsQiSCgl2IRFCwC5EISy44CUwmRNZwLpUhC9uykssxrSycFQQA2w0ur1X6XJKpIix31H2Tjlmr9qkNDV5kM6KUIaIOojcJyz+NEc/mQzUsKQJAt8elpjJSTHM8DTu5DV6cc9yOFJXsRqRZrqRi6OFLvDri8mW1jBTZvBaR3ta5TLlT59dBp9cNbp+c4tdwg7WTchWcFCJ5FOxCJIKCXYhEULALkQgKdiESQcEuRCIsVXpzd0xJzzGvcUljRvpXFR2uuWRVrl21dyOS0YzLHaPx6eD2Brp0zHDIdTKrRHqlVXjmVb3BxzXycKbUdNamY8Y5lzAbQy5RxWSe4SCc5VXucgkwclporXJptp9HCn7WwvM46/JroJhF5MYWn6vR5Bq1nY5kMTo5nCOS3TjuBreXzv3TnV2IRFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJsFTpLXPDyiycGVRf4xlDu0VYTuo3ubxWAy/WN7uDS3bVVkQa2gzLGjtdvr9BOFFufixEii9WuTTUrEYKbSI8j5Uql5OmEbnGnWebIZJ1OJuF578Y8Pm1lXVqyyJFJetVPo/TCpHsSH81AGhEet9VO3zu2w0eTo27+PG8FfZxVudy4xpR5TI+FbqzC5EKCnYhEkHBLkQiKNiFSAQFuxCJsOdqvJk1AHwPQH3x/L9w90+a2b0AvgrgBIAfAPiwu0eyJuZl5iat8KpwtcITRpqt8Pas5Icb5TzxY5UkRwCAt3k9tvWN8Crt4ARxEECFL+xiFmy0M6cgteQAIKty/1ktvyKStDKOtFby4tZW6stmOBFmZYWrLs0Jfz0ra7w2YBGprzcah+v8eaTdmJeR1mFN7ketxe+dmy2uDuX18JyU2Qk6prcRthWRAoX7ubOPAfymu/8a5u2ZHzCzdwH4UwCfc/d/CWAbwEf2sS8hxDGxZ7D7nNdKY+aLfw7gNwH8xWL74wDedxQOCiEOh/32Z68sOrheAfBdAP8IoOv+T7/GuAjg7JF4KIQ4FPYV7O5euPt9AN4C4H4Av7zfA5jZw2Z2wcwubG93b8lJIcTBeVOr8e7eBfBXAP4VgHUze22B7y0AXiZjzrv7OXc/t7GxfgBXhRAHYc9gN7NTZra+eNwE8NsAnsc86H9v8bSHAHz7iHwUQhwC+0mEOQPgcTOrYP7m8HV3/59m9hMAXzWz/wDgbwF8aa8dFdMZupevBG2NO7k0Ua2sh8cUXPKyGm+tNJry97i8weUwwzC4vb7K5bpixmWyTs5lqNJ5kk+kdB0sC/vvJR80ich8k4j/5TQiXzXCtfwmnfAcAkAtkiRTidQbLGaRunDD8DxOZvz6yHMuU+YZl7baEXlwGpE3K9WwjNZZ4a/L1cHF4PaiiLS1opYF7v4MgHcEtv8M8+/vQoh/BugXdEIkgoJdiERQsAuRCAp2IRJBwS5EIphHsqEO/WBmVwG8uPjzJADeL2d5yI/XIz9ezz83P/6Fu58KGZYa7K87sNkFdz93LAeXH/IjQT/0MV6IRFCwC5EIxxns54/x2DcjP16P/Hg9vzB+HNt3diHEctHHeCES4ViC3cweMLO/M7Ofmtkjx+HDwo8XzOxZM3vazC4s8biPmdkVM3vupm2bZvZdM/uHxf8bx+THo2b28mJOnjaz9y7Bj7vN7K/M7Cdm9mMz+7eL7Uudk4gfS50TM2uY2d+Y2Y8Wfnxqsf1eM3tqETdfMzOeghfC3Zf6D0AF87JWvwSgBuBHAN6+bD8WvrwA4OQxHPc3ALwTwHM3bfuPAB5ZPH4EwJ8ekx+PAvjjJc/HGQDvXDzuAPh7AG9f9pxE/FjqnAAwAO3F4xzAUwDeBeDrAD642P5fAPzhm9nvcdzZ7wfwU3f/mc9LT38VwIPH4Mex4e7fA7D1hs0PYl64E1hSAU/ix9Jx90vu/sPF4x7mxVHOYslzEvFjqficQy/yehzBfhbASzf9fZzFKh3AX5rZD8zs4WPy4TVOu/ulxeNXAZw+Rl8+ZmbPLD7mH/nXiZsxs3swr5/wFI5xTt7gB7DkOTmKIq+pL9C9293fCeDfAPiomf3GcTsEzN/ZgUg/56PlCwDeinmPgEsAPrOsA5tZG8A3AHzc3W/cbFvmnAT8WPqc+AGKvDKOI9hfBnD3TX/TYpVHjbu/vPj/CoBv4Xgr71w2szMAsPg/XL/riHH3y4sLrQTwRSxpTswsxzzAvuzu31xsXvqchPw4rjlZHLuLN1nklXEcwf59AG9brCzWAHwQwBPLdsLMWmbWee0xgN8B8Fx81JHyBOaFO4FjLOD5WnAteD+WMCdmZpjXMHze3T97k2mpc8L8WPacHFmR12WtML5htfG9mK90/iOAf3dMPvwS5krAjwD8eJl+APgK5h8Hp5h/9/oI5j3zngTwDwD+D4DNY/LjvwF4FsAzmAfbmSX48W7MP6I/A+Dpxb/3LntOIn4sdU4A/CrmRVyfwfyN5U9uumb/BsBPAfwPAPU3s1/9gk6IREh9gU6IZFCwC5EICnYhEkHBLkQiKNiFSAQFuxCJoGAXIhEU7EIkwv8HW3ALeDQZZ4UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = vae.sample(2)\n",
    "ims = samples.to('cpu').detach().numpy()\n",
    "im0 = ims[0].swapaxes(0, 2).swapaxes(0, 1)\n",
    "plt.imshow(im0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5cbd0",
   "metadata": {},
   "source": [
    "Test against a clean VAE that has not been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91b5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae_clean = VariationalAutoencoder(device).to(device)\n",
    "samples = vae_clean.sample(2)\n",
    "ims = samples.to('cpu').detach().numpy()\n",
    "im0 = ims[0].swapaxes(0, 2).swapaxes(0, 1)\n",
    "\n",
    "plt.imshow(im0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6ae55",
   "metadata": {},
   "source": [
    "### Variational autoencoders with normalising flows\n",
    "\n",
    "Set up the hyperparameters, and construct the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "504f83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "n_bottleneck = 64\n",
    "n_flows = 8\n",
    "\n",
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
    "\n",
    "# Specify the flow layers\n",
    "b = torch.tensor(n_bottleneck // 2 * [0, 1] + n_bottleneck % 2 * [0])\n",
    "flows = []\n",
    "for i in range(n_flows):\n",
    "    st_net = MLP(n_bottleneck, 1024, 3)\n",
    "    if i % 2 == 0:\n",
    "        flows += [LatentMaskedAffineCoupling(b, st_net)]\n",
    "    else:\n",
    "        flows += [LatentMaskedAffineCoupling(1 - b, st_net)]\n",
    "\n",
    "# Specify the prior (target distribution)\n",
    "# prior = torch.distributions.MultivariateNormal(\n",
    "#     torch.zeros(n_bottleneck, device=device),\n",
    "#     torch.eye(n_bottleneck, device=device)\n",
    "#     )\n",
    "prior = torch.distributions.normal.Normal(loc=0.0, scale=1.0)\n",
    "        \n",
    "# Construct the normalising flow\n",
    "nf = NormalisingFlow(flows, prior, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f9ff84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss(x, y):\n",
    "    return torch.sum((x - y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e1609c",
   "metadata": {},
   "source": [
    "Instantiate a VAE with normalising flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f7a353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_nf = VariationalAutoencoder(device, flows=nf, latent_size=n_bottleneck).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc21ba",
   "metadata": {},
   "source": [
    "Train the VAE-NF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ec8afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [10496/42000 (100%)]\tLoss: 868.067993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10496/42000 (100%)]\tLoss: -21.193848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [10496/42000 (100%)]\tLoss: -779.310303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [10496/42000 (100%)]\tLoss: -1062.648193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 23.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [10496/42000 (100%)]\tLoss: -1273.984131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [10496/42000 (100%)]\tLoss: -1320.980713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [10496/42000 (100%)]\tLoss: -1558.102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 23.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [10496/42000 (100%)]\tLoss: -1695.651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [10496/42000 (100%)]\tLoss: -1766.254395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [10496/42000 (100%)]\tLoss: -2030.025146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [10496/42000 (100%)]\tLoss: -1923.723755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 23.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [10496/42000 (100%)]\tLoss: -2214.815430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [10496/42000 (100%)]\tLoss: -2304.502441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 23.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [10496/42000 (100%)]\tLoss: -2350.472168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [10496/42000 (100%)]\tLoss: 1817499.250000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [10496/42000 (100%)]\tLoss: 7039.498535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:28<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [10496/42000 (100%)]\tLoss: 9265.075195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [10496/42000 (100%)]\tLoss: 14461.925781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [10496/42000 (100%)]\tLoss: 8925.414062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:27<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [10496/42000 (100%)]\tLoss: 10051.555664\n"
     ]
    }
   ],
   "source": [
    "optimizer =  torch.optim.Adam(vae_nf.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "for epoch in range(n_epochs):\n",
    "    progressbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for batch_n, (x, n) in progressbar:\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, mu, sigma, var_loss = vae_nf(x)\n",
    "        loss = var_loss + recon_loss(x, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progressbar.update()\n",
    "    progressbar.close()\n",
    "    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_n * len(x), len(train_loader.dataset),\n",
    "                       100. * batch_n / len(train_loader),\n",
    "                       loss.item()))\n",
    "    \n",
    "torch.save(vae_nf.state_dict(), \"../../nf_tutorial/saved_models/vae_nf.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1aa3b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = vae_nf.sample(2)\n",
    "ims = samples.to('cpu').detach().numpy()\n",
    "im0 = ims[0].swapaxes(0, 2).swapaxes(0, 1)\n",
    "plt.imshow(im0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833d3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
